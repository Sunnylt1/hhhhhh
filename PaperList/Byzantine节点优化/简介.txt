《A Little Is Enough: Circumventing Defenses For Distributed Learning》
即使是iid数据，本文提出的方法也能在不会被检测出异常的范围内，针对不同的聚合方式制造扰动攻击（并且是non-omniscient攻击）和Backdoor Attack，降低模型准确性或者收敛性。
因为假设了正态和独立同分布，所以不需要知道其它节点的数据，知道本节点的数据就足够推断均值和标准差了。

《Abnormal Client Behavior Detection in Federated Learning》（微众银行）
在联邦学习中，当用户上传的中心服务器的权重受到攻击时，detection-based的方法比传统的defense-based方法更加有效（本文使用的是Autoencoder-Based异常检测）。使用credit score来代替原权重计算中的各节点数据点比例，credit score由异常检测模型的anomaly score给出。

《Adversary-resilient Inference and Machine Learning: From Distributed to Decentralized》
关于中心化和去中心化结构的Byzantine攻击和抵抗做了一个综述，可参考的文章较多

《Adversary-Resilient Distributed and Decentralized Statistical Inference and Machine Learning》
有中心和无中心分布式的综述，列举了常见的抵抗攻击的方法。

《AKSEL: Fast Byzantine SGD》
提出了median-based的聚合方法，Aksel。这种方法时间复杂度较低，对恶意节点的容忍程度是n>2f，同时，聚合后的梯度与真实梯度之间的Angular error也更小。

《Approximate Byzantine Fault-Tolerance in Distributed Optimization》
相对于exact fault-tolerance的概念而言，提出了更加宽松的approximate fault-tolerance在得到近似最优解。（(f, ε)-resilience）

《Asynchronous Byzantine Machine Learning (the case of SGD)》
分布式异步SGD算法对抗恶意节点，Krum的合作者写的。

《Auto-weighted Robust Federated Learning with Corrupted Data Sources》
Auto-weighted Robust Federated Learning (ARFL)：通过比较每个节点的经验风险与最佳的p个节点的平均经验风险（p-average）来分配权重，可以降低损失明显更高的节点的权重，从而降低他们对全局模型的贡献

《Byzantine Fault-Tolerant Distributed Machine Learning Using Stochastic Gradient Descent (SGD) and Norm-Based Comparative Gradient Elimination (CGE)》
有中心的分布式SGD，i.i.d
提出了一种新的鲁棒聚合方法：comparative gradient elimination (CGE)，中心节点收到n个随机梯度，去掉欧式范数最大的f个随机梯度，用剩下n-f个梯度做aggregation（这里用的是均值）

《Byzantine Fault-Tolerant Parallelized Stochastic Gradient Descent for Linear Regression》
使用comparative gradient clipping (CGC)来提供算法鲁棒性。在有中心的网络中，每次把最大的f个（假设知道恶意节点数f）梯度做clipping操作：保留原梯度方向，但是scaler是第f+1个梯度的大小。其它梯度不变，聚合方法还是均值。

《BYZANTINE-RESILIENT DECENTRALIZED LEARNING》
一篇无中心的抵抗Byzantine攻击的博士论文，主要分析了三种Byzantine-resilient方法：
1.收到邻居节点的信息后，先使用SVM做二分类筛选再进行计算
2.Empirical Risk Minimization (ERM)问题在Byzantine网络中无法被exactly solved，但是本文提出的Byzantine-Resilient Decentralized coordinate dEscent (ByRDiE)能够在统计上实现probably and approximately correct (PAC)  Learnable.
3.ByRDiE需要scalar sorting process，不适用于向量和矩阵情况，因此引入梯度下降Byzantine-resilient decentralized gradient descent (BRIDGE)

《Byzantine-Resilient Multi-Agent Optimization》
引入 (β,γ)–admissibility来评价无中心分布式网络的Byzantine-resilience

《Byzantine Resilient Non-Convex SVRG with Distributed Batch Gradient Computations》
在有Byzantine节点的有中心分布式网络中，基于SVRG提出了分布式的SCSG算法来解决非凸问题

《Byzantine-Resilient Secure Federated Learning》
Byzantine-resilient secure aggregation(BREA)特点：
i) robustness of the trained model against up to A Byzantine adversaries, 
ii) tolerance against up to D user dropouts, iii) privacy of each local model, against the server and up to T colluding users, as long asN≥2A+1+max{m+2,D+2T},where m is the number of selected models for aggregation.

《Byzantine-Robust Learning on Heterogeneous Datasets via Resampling》
有中心的分布式，non-iid
1.设计了新的攻击来绕过防御（normalized gradient和mimic可以利用数据异构性绕过中值方法和符号聚合方法）
2.将重采样与原有鲁棒算法结合抵抗攻击

《Byzantine Stochastic Gradient Descent》
提出了一种算法（ByzantineSGD），并分析了它的运行效率和抵抗能力
恶意节点容忍度<1/2

《Byzantine-Tolerant Machine Learning》
（是《Machine Learning with Adversaries Byzantine Tolerant Gradient Descent》的完善版本）
提出Krum并说明线性聚合方式对于抵抗攻击是无效的
提出并应用(α, f)-Byzantine resilience，证明Krum的收敛性（聚合方式有基于聚合和基于多数，krum属于基于多数）
另外，证明了收敛的计算时间为O(n2 · (d + log n))，n是节点数量，d是特征维数

《Detection and Isolation of Adversaries in Decentralized Optimization for Non-Strongly Convex Objectives》
针对非强凸目标优化问题，提出了一种检测和隔离恶意节点的去中心鲁棒算法：decentralized robust subgradient push (RSGP)（基于Push-Sum）

《Distributed Byzantine Tolerant Stochastic Gradient Descent in the Era of Big Data》
提出了两种不限制恶意节点数量上限（45/50依然有效）的Byzantine tolerant SGD算法。
当恶意节点数上界p已知时：
计算节点收集离自己距离最近的N-p-1个节点的参数，取均值后用来更新自己的参数（更新后需要加归一化步骤）
当恶意节点数上界p已知时：
选择离自己足够近且参数下降方向一致的节点的参数，取均值后更新。
（一个想法：每轮迭代节点选择时需要所有节点间参数共享，中心节点通讯压力较大？）

《DETOX: A Redundancy-based Framework for Faster and More Robust Gradient Aggregation》
（有中心）DETOX结合了算法冗余robust aggregation和鲁棒聚合algorithmic redundancy，分为两个步骤：1.filtering step，用冗余来削弱恶意节点的影响，2.hierarchical aggregation step，与sota的鲁棒聚合方法结合。其中第二步也有两个小步骤，首先将过滤后的梯度划分为少量组进行聚合，然后对平均梯度使用鲁棒聚合以进一步最小化拜占庭梯度的剩余痕迹影响

《Distributed Momentum for Byzantine-resilient Learning》
在有中心的网络节点中，worker使用动量能够减少主节点收到的好节点的variance-norm ratio，增强聚合鲁棒性。
 Momentum consists in summing a series of past gradients with the new one using an exponential decay factor μ (0 < μ < 1), instead of using the new gradient alone.

《Distributed Newton Can Communicate Less and Resist Byzantine Workers》
有中心，高效沟通的分布式二阶优化算法，COMRADE (COMunication-efficient and Robust Approximate Distributed nEwton)。worker先压缩信息再发送（梯度和Hessian矩阵），每个worker每次迭代只向中心节点发送一次信息。
抵抗方式：基于范数的梯度过滤（对范数最小的一部分梯度取均值）

《Distributed Optimization Under Adversarial Nodes》
无中心的分布式优化问题
1.证明了不存在“既能在无攻击情况下找到最优解，又能抵御设计好的攻击”的算法
2.介绍了Local Filtering (LF) Dynamics这种consensus-based的分布式优化协议，并研究了F-local和F-total在不同攻击下的表现情况
3.在一定条件下，未遭受攻击的节点能够收敛到他们本地目标函数的最小值的凸包内
4. Maximum F-local sets的规模越大，算法安全性越差；The size of themaximum F-local sets是一个NP-hard问题。

《Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent》
较早的一篇（2017），分析了几何中值做抵抗时的算法复杂度
证明（依概率）一致收敛，参数以一定的误差在O(logN)次迭代收敛
一个特点：节点极多，做中值操作之前还需要先mini-batch
恶意节点容忍度：2(1 + ε )q ≤ m 

《Dynamic Federated Learning Model for Identifying Adversarial Clients》
通过动态地判断恶意节点并摒除恶意节点信息提高模型训练效果并减轻训练代价。
原理：（Induced Ordered Weighted Averaging (IOWA) operator）根据对聚合过程中每个节点的贡献做加权。

《Fall of Empires Breaking Byzantine-tolerant SGD by Inner Product Manipulation》
证明在inner production manipulation攻击下coordinate-wise median和Krum方法可能是不可靠的。
“基本想法是当接近最优解时，正常节点的平均随机梯度接近于0，那么即使median和krum能够保证聚合结果离正常节点的平均随机梯度很近，方向也有可能是相反的”
最后文章提出需要修改关于Byzantine Tolerance的定义（Definition 4. (DSSGD-Byzantine Tolerance)）

《Fast Machine Learning with Byzantine Workers and Servers》
（”刘备“算法，之前有过关羽和张飞了）
1.假设所有节点和服务器均不可信
2.与non-Byzantine resilient algorithms相比，不产生额外的通信轮次
3.本文机制：建立在梯度聚合规则（GAR）上来抵抗攻击，通过从worker节点的副本中过滤出信息（从多台机器上复制参数服务器，但不信任这些服务器）

《Fault-Tolerance in Distributed Optimization: The Case of Redundancy》
有中心、无中心情况都有考虑。
只有当好节点有minimal redundancy性质时，才能最小化好节点之间的aggregate cost
[2f-redundancy] For a given set of non-faulty agents H, their non-faulty cost functions are said to satisfy 2f - redundancy if for every subset S ⊆ H of size at least n − 2f ,
argmin 􏰵\sum_{i∈S} Q_i(w) = argmin 􏰵 􏰵\sum_{i∈H} Q_i(w).
抵抗方式：comparative gradient clipping (CGC)

《Federated Machine Learning: Concept and Applications》
杨强的联邦学习

《Generalized Byzantine-tolerant SGD》
基于(α, f)-Byzantine resilience的理论，证明了几何中值等三种中值方法的收敛性
另外也提到了计算开销的复杂度问题

《Holdout SGD: Byzantine Tolerant Federated Learning》
1.从所有节点中，随机抽P个用来计算梯度，随机抽C个用来投票
2.P个节点算出各自的随机梯度后发给中心节点，中心节点把收到的随机梯度发送给C个投票节点，每个投票节点把收到的P个随机梯度带入自己节点的损失函数做计算，然后把“P·(1-f) 个损失函数最小的随机梯度”对应的节点作为自己的投票结果返回给中心节点
3.中心节点收到C个投票节点的投票结果（对P投票），在投票结果中取交集，用这些随机梯度的均值更新
无中心、有中心情况都有讨论。无中心模式下算法更复杂一点
Byzantine节点要求：有中心<1/2，无中心<1/3

《Learning from History for Byzantine Robust Optimization》
目前其他robust aggregation rules的问题：
1.目前的鲁棒聚合方法因为对噪音敏感，所以都会diverge（即使没有Byzantine节点干扰）
2.即使一轮攻击会被aggregation消除，多轮攻击（跨时间）下依然会有divergence
本文算法特点：gradient clipping+momentum+nonconvex
（包装的很好，不过稍微有点overclaim）

《Learning to Detect Malicious Clients for Robust Federated Learning》
本文用标准SGD更新，假设恶意攻击是加入i.i.d.的noise，使用spectral anomaly detection方法来检测出恶意节点，更新时移除一定数量的恶意节点。
具体来说，作者认为没有噪声（攻击）时，数据可以嵌入一个低维空间；而恶意节点嵌入的误差会明显要大。因此训练一个encoder-decoder可以找到恶意节点——它们的误差会大。然后通过设置自适应的阈值，可以移除一些恶意节点。
理论只考虑了线性模型+L2损失时恶意攻击的影响。主要还是一篇实作型文章。

《Local Model Poisoning Attacks to Byzantine-Robust Federated Learning》
1、这篇文章主要的想法是设计特定的攻击方式，使得现有鲁棒算法学到的模型往错误的方向走。思路与Cong Xie, Sanmi Koyejo, and Indranil Gupta. Fall of empires: Breaking byzantine-tolerant sgd by inner product manipulation这篇文章很接近。
2、作者区分了data poisoning attack与local model poisoning attack。个人觉得，在用基于SGD的算法时，这两种攻击差距不大。
3、这篇文章最大的问题是假设数据不是i.i.d.的。从图三可以看出来，大部分鲁棒算法（除了Krum）在i.i.d.情况下表现都不错，但non-i.i.d.情况下性能就下降很快。说明作者没有认真的研究现有鲁棒算法的基本假设。
4、这篇文章还设计了两种防御方法，基本思路是在中心节点引入额外的测试样本帮助识别可能的恶意攻击。本质上可以认为是一种利用redundant data抵抗攻击的方法，但复杂度比较高。

《Machine Learning with Adversaries Byzantine Tolerant Gradient Descent》
（《Byzantine-Tolerant Machine Learning》的初期版本）
提出了Krum，并简述了(α，f)收敛性，更偏向于sketch，附有部分证明

《Mitigating Sybils in Federated Learning Poisoning》
女巫攻击的抵抗。在上面大部分Byzantine resilience文章中，恶意节点的数量不超过一定数量几乎是一项必然要求，但实际中，恶意用户可以试图创建多个属于自己的节点，轻而易举地攻破上面majority based的算法。这种攻击方式就叫女巫攻击。
研究女巫攻击的文章不多，这里补充一篇，文章提出了FoolsGold算法。然而这篇文章抵抗女巫攻击的立足点是在城市节点的Non-IID性质和女巫攻击节点的相似性上。诚实节点返回信息不相似，女巫节点之间非常相似，因而可以设法把他们分辨开来。
理论上这种方式和原来的要求恶意节点不能太多的要求并没有什么不同。对城市节点充分Non-IID的要求限制了算法可用性。该文仅供参考。

《ON DISTRIBUTED STOCHASTIC GRADIENT DESCENT FOR NONCONVEX FUNCTIONS IN THE PRESENCE OF BYZANTINES》
有中心的分布式SGD，α < 1/2，可用于非凸目标函数
设计了一个新的方法来抵抗Byzantine攻击：
g_{t+1} = { i∈g_{t} :|A_{i}^(t) −A_{med}^(t) | ≤ 4M^2 T ∩ ||∇_{i,t} − ∇_med|| ≤ 4v }
其中
A_{i}^(t) = sum_{t} 􏰓⟨∇_{i,t} ,∇_{0,t} ⟩
A_{med}^(t) = med{A_{1}^(t),...,A_{w}^(t)}

《On the Design of Communication Efficient Federated Learning over Wireless Networks》
在SignSGD中，模型表现依赖于两个因素：1.有限时间内的信息交互轮数（信息交换速度）；2.信息交互时的中断概率。
本文研究了两个tradeoff：1.单轮信息交互的时间给定时，中断概率和能耗的tradeoff；2.能耗给定时，信息交互轮数和中断概率的tradeoff。

《Resilient Distributed Optimization Algorithms for Resource Allocation》
提出基于resilient primal-dual的方法，将一种恢复均值点的聚合方法与primal-dual data resource allocation（PD-DRA）方法结合起来，依然是有中心的结构，Byzantine节点<1/2

《Resilient Multi-Robot Target Pursuit》
无中心情况，可以忍受n个邻居中[n/d-1] − 1个恶意节点
抵抗方式：基于中心点的，高维空间的广义中值算法，好节点可以保证把中心点落在它的好邻居的凸包内。

《Robust federated learning in a heterogeneous environment》
在数据是非iid的情况下（Heterogeneous），通过cluster解决联邦学习中的Byzantine攻击问题。
从统计意义上证明了Lloyds算法的可靠性（Lloyds与k-means有一些区别，但文中似乎没有区分）

《Secure Byzantine-Robust Machine Learning》
在有Byzantine攻击的分布式问题下，提出了 two-server protocol.
secure aggregation rule + two non-colluding honest-but-curious servers

《SGD: Decentralized Byzantine Resilience》
GUANYU：异步更新，容忍1/3的恶意节点
基于(α, f)-Byzantine resilient的Gradient Aggregation Rules (GARs)
提到了一些攻击方法，可以参考。另外作为写作指导也很不错

《Stochastic-Sign SGD for Federated Learning with Theoretical Guarantees》
Sign SGD在每轮迭代的主从节点信息交换中只传递梯度符号和aggregation值，效率很高但是在异质的分布下不收敛。本文提出的stochastic-sign SGD和 differentially private sign SGD算法可以在异质数据分布下也达到收敛的效果，而且收敛率与同质情况相同。
（作者金日成Sign SGD相关论文还有两篇：Distributed Byzantine Tolerant Stochastic Gradient Descent in the Era of Big Data 和 On the Design of Communication Efficient Federated Learning over Wireless Networks）

《The Hidden Vulnerability of Distributed Learning in Byzantium》
提出一种针对Krum和Geometric Median等基于范数的鲁棒聚合算法的攻击以及对应的防御算法Bulyan。
Krum和GeoMed抵抗攻击能力都强烈依赖于诚实节点之间梯度的一致性。当诚实节点间梯度不一致时，这种分歧会留给攻击者一定的操作空间。文章构造的这种攻击就是利用这种分歧掩盖这种攻击，并在所留下的操作空间里尝试控制最终的聚合结果，这种攻击对Krum和GeoMed破坏力极大。
文章提出Bulyan算法，可以看作Krum和GeoMed的堆叠版本。算法先计算通常的Krum和GeoMed，选出梯度集合里最靠近聚合结果的梯度，拿出来并记录，多次重复。对这些拿出来的梯度进行简单平均，就是聚合算法Bulyan。

《Towards Byzantine-resilient Learning in Decentralized Systems》
无中心情况下的Byzantine问题。提出了MOZI（墨子）聚合方法，该方法对Byzantine的节点数不作要求（甚至是可变的）。
在有中心的情况下，Byzantine-resilient方法主要分为基于距离（Distance-based solutions）和目标函数（Performance-based Solutions）两种类型。现有的去中心化Byzantine-resilient方法大多是基于距离做聚合，对特定的攻击抵抗力较弱（Mhamdi[20],[25],[26]）。
在迭代过程中，各节点使用邻居节点的aggregation和该节点的目标函数负梯度来更新。
本文使用的是aggregation算法MOZI的思路是：
1.基于距离在邻居节点中选出可能的好节点集合
2.基于目标函数表现再选一次（不需要另外准备测试集，依然使用训练数据）
注：
有收敛性分析，但没有看到关于Byzantine节点数量任意性的分析（如果过半，第一步就垮了）

《Zeno: Byzantine-suspicious stochastic gradientdescent》
第一个证明了Byzantine节点数量多的时候也能收敛：majority-based algorithms可能会失败，suspicion-based algorithm能够解决这个问题
从限制方差的角度来证明
基于方法的证明，暂时不用看
注：
本文提出的算法基于一个假设：byzantine节点在攻击时不知道正常节点上传的梯度
